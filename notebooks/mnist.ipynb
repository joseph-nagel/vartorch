{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian neural net (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightning.pytorch import seed_everything, Trainer\n",
    "\n",
    "from vartorch import (\n",
    "    MNISTDataModule,\n",
    "    ConvVarClassifier,\n",
    "    anomaly_score,\n",
    "    plot_post_predictions,\n",
    "    plot_entropy_histograms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = seed_everything(111111)  # set random seeds manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNISTDataModule(\n",
    "    data_set='mnist',\n",
    "    data_dir='../run/data/',\n",
    "    mean=0.5,\n",
    "    std=0.5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "mnist.prepare_data()  # download data if not yet done\n",
    "mnist.setup(stage='test')  # create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = mnist.test_dataloader()\n",
    "x_batch, y_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(5, 4.5))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = mnist.renormalize(x_batch[idx, 0]).numpy()\n",
    "    ax.imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(mnist.test_set.classes[y_batch[idx]])\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_file = '../run/mnist/version_0/checkpoints/last.ckpt'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "var_model = ConvVarClassifier.load_from_checkpoint(ckpt_file)\n",
    "\n",
    "var_model = var_model.to(device)\n",
    "var_model = var_model.train(False)\n",
    "\n",
    "print(f'Train mode: {var_model.training}')\n",
    "print(f'Sampling: {var_model.sampling}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(logger=False)\n",
    "\n",
    "test_metrics = trainer.test(\n",
    "    model=var_model,\n",
    "    dataloaders=mnist.test_dataloader(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist = MNISTDataModule(\n",
    "    data_set='kmnist',\n",
    "    data_dir='../run/data/',\n",
    "    mean=0.5,\n",
    "    std=0.5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "kmnist.prepare_data()  # download data if not yet done\n",
    "kmnist.setup(stage='test')  # create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_set = mnist.test_set\n",
    "anom_set = kmnist.test_set\n",
    "\n",
    "norm_loader = mnist.test_dataloader()\n",
    "anom_loader = kmnist.test_dataloader()\n",
    "\n",
    "x_norm, y_norm = next(iter(norm_loader))\n",
    "x_anom, y_anom = next(iter(anom_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random images\n",
    "plot_ids = np.random.permutation(len(x_norm))\n",
    "\n",
    "# select images with lowest prediction entropy\n",
    "# plot_ids = torch.argsort(point_anom_entropy, descending=False).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "\n",
    "var_model.train(False)  # turn off train mode\n",
    "var_model.sample(True)  # turn on sampling\n",
    "\n",
    "with torch.no_grad():\n",
    "    sampled_norm_logits = var_model.predict(x_norm.to(var_model.device), num_samples).cpu()\n",
    "    sampled_norm_probs = torch.softmax(sampled_norm_logits, dim=1)\n",
    "\n",
    "    sampled_anom_logits = var_model.predict(x_anom.to(var_model.device), num_samples).cpu()\n",
    "    sampled_anom_probs = torch.softmax(sampled_anom_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior predictions (in distribution)\n",
    "fig, axes = plot_post_predictions(\n",
    "    images=mnist.renormalize(x_norm[plot_ids]),\n",
    "    sampled_probs=sampled_norm_probs[plot_ids],\n",
    "    labels=y_norm[plot_ids],\n",
    "    names=norm_set.classes,\n",
    "    nrows=3,\n",
    "    figsize=(8, 6),\n",
    "    title='Posterior predictions (in distribution)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior predictions (out of distribution)\n",
    "fig, axes = plot_post_predictions(\n",
    "    images=kmnist.renormalize(x_anom[plot_ids]),\n",
    "    sampled_probs=sampled_anom_probs[plot_ids],\n",
    "    labels=y_anom[plot_ids],\n",
    "    names=anom_set.classes,\n",
    "    nrows=3,\n",
    "    figsize=(8, 6),\n",
    "    title='Posterior predictions (out of distribution)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-distribution detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_norm_entropy = anomaly_score(\n",
    "    var_model,\n",
    "    norm_loader,\n",
    "    mode='entropy',\n",
    "    num_samples=100\n",
    ")\n",
    "\n",
    "var_anom_entropy = anomaly_score(\n",
    "    var_model,\n",
    "    anom_loader,\n",
    "    mode='entropy',\n",
    "    num_samples=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior entropy histogram\n",
    "fig, ax = plot_entropy_histograms(\n",
    "    norm_entropy=var_norm_entropy,\n",
    "    anom_entropy=var_anom_entropy,\n",
    "    figsize=(6, 4),\n",
    "    range=(0, 2),\n",
    "    bins=100,\n",
    "    title='Posterior predictive'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
