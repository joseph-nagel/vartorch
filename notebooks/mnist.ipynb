{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian neural net (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "from vartorch import (\n",
    "    MNISTDataModule,\n",
    "    ConvVarClassifier,\n",
    "    anomaly_score,\n",
    "    plot_point_predictions,\n",
    "    plot_post_predictions,\n",
    "    plot_entropy_histograms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = seed_everything(111111) # set random seeds manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNISTDataModule(\n",
    "    data_set='mnist',\n",
    "    data_dir='../run/data/',\n",
    "    mean=0.5,\n",
    "    std=0.5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "mnist.prepare_data() # download data if not yet done\n",
    "mnist.setup(stage='test') # create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = mnist.test_dataloader()\n",
    "x_batch, y_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(5, 4.5))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    image = x_batch[idx, 0].numpy() / 2 + 0.5\n",
    "    ax.imshow(image, cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(mnist.test_set.classes[y_batch[idx]])\n",
    "    ax.set(xticks=[], yticks=[], xlabel='', ylabel='')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_file = '../run/mnist/version_0/checkpoints/last.ckpt'\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = ConvClassifier.load_from_checkpoint(ckpt_file)\n",
    "\n",
    "# model = model.eval()\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_file = '../run/mnist/version_0/checkpoints/last.ckpt'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "var_model = ConvVarClassifier.load_from_checkpoint(ckpt_file)\n",
    "\n",
    "var_model = var_model.eval()\n",
    "var_model = var_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmnist = MNISTDataModule(\n",
    "    data_set='kmnist',\n",
    "    data_dir='../run/data/',\n",
    "    mean=0.5,\n",
    "    std=0.5,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "kmnist.prepare_data() # download data if not yet done\n",
    "kmnist.setup(stage='test') # create test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_loader = mnist.test_dataloader()\n",
    "anom_loader = kmnist.test_dataloader()\n",
    "\n",
    "norm_set = mnist.test_set\n",
    "anom_set = kmnist.test_set\n",
    "\n",
    "norm_images, norm_labels = next(iter(norm_loader))\n",
    "anom_images, anom_labels = next(iter(anom_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random images\n",
    "plot_ids = np.random.permutation(np.arange(len(x_batch)))\n",
    "\n",
    "# select images with lowest prediction entropy\n",
    "# plot_ids = torch.argsort(point_anom_entropy, descending=False).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     point_norm_probs = model.predict_proba(norm_images.to(model.device)).cbpu()\n",
    "#     point_anom_probs = model.predict_proba(anom_images.to(model.device)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot point predictions (in distribution)\n",
    "# fig, axes = plot_point_predictions(\n",
    "#     images=x_batch[plot_ids],\n",
    "#     probs=point_norm_probs[plot_ids],\n",
    "#     labels=y_batch[plot_ids],\n",
    "#     names=norm_set.classes,\n",
    "#     nrows=3,\n",
    "#     figsize=(5, 6),\n",
    "#     title='Point predictions (in distribution)'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot point predictions (out of distribution)\n",
    "# fig, axes = plot_point_predictions(\n",
    "#     images=x_batch[plot_ids],\n",
    "#     probs=point_anom_probs[plot_ids],\n",
    "#     labels=y_batch[plot_ids],\n",
    "#     names=norm_set.classes,\n",
    "#     nrows=3,\n",
    "#     figsize=(5, 6),\n",
    "#     title='Point predictions (out of distribution)'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "\n",
    "var_model.sample(True)\n",
    "var_model.train(False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sampled_norm_logits = var_model.predict(norm_images.to(var_model.device), num_samples).cpu()\n",
    "    sampled_norm_probs = torch.softmax(sampled_norm_logits, dim=1)\n",
    "\n",
    "    sampled_anom_logits = var_model.predict(anom_images.to(var_model.device), num_samples).cpu()\n",
    "    sampled_anom_probs = torch.softmax(sampled_anom_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior predictions (in distribution)\n",
    "fig, axes = plot_post_predictions(\n",
    "    images=x_batch[plot_ids],\n",
    "    sampled_probs=sampled_norm_probs[plot_ids],\n",
    "    labels=y_batch[plot_ids],\n",
    "    names=norm_set.classes,\n",
    "    nrows=3,\n",
    "    figsize=(8, 6),\n",
    "    title='Posterior predictions (in distribution)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior predictions (out of distribution)\n",
    "fig, axes = plot_post_predictions(\n",
    "    images=x_batch[plot_ids],\n",
    "    sampled_probs=sampled_anom_probs[plot_ids],\n",
    "    labels=y_batch[plot_ids],\n",
    "    names=anom_set.classes,\n",
    "    nrows=3,\n",
    "    figsize=(8, 6),\n",
    "    title='Posterior predictions (out of distribution)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-distribution detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_entropy = anomaly_score(model, norm_loader, mode='entropy')\n",
    "# anom_entropy = anomaly_score(model, anom_loader, mode='entropy')\n",
    "\n",
    "var_norm_entropy = anomaly_score(var_model, norm_loader, mode='entropy', num_samples=100)\n",
    "var_anom_entropy = anomaly_score(var_model, anom_loader, mode='entropy', num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot point entropy histogram\n",
    "# fig, ax = plot_entropy_histograms(\n",
    "#     norm_entropy=var_norm_entropy,\n",
    "#     anom_entropy=var_anom_entropy,\n",
    "#     figsize=(6, 4),\n",
    "#     range=(0, 2),\n",
    "#     bins=100,\n",
    "#     title='Point predictions'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot posterior entropy histogram\n",
    "fig, ax = plot_entropy_histograms(\n",
    "    norm_entropy=var_norm_entropy,\n",
    "    anom_entropy=var_anom_entropy,\n",
    "    figsize=(6, 4),\n",
    "    range=(0, 2),\n",
    "    bins=100,\n",
    "    title='Posterior predictive'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
