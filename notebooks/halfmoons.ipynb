{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian neural net: half-moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../torchutils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torchutils import Classification\n",
    "\n",
    "from vartorch import (\n",
    "    plot_data_2d,\n",
    "    plot_function_2d,\n",
    "    VariationalLinear,\n",
    "    VariationalClassification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds manually\n",
    "np.random.seed(123456789)\n",
    "_ = torch.manual_seed(987654321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half-moons data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "noise_level = 0.15\n",
    "\n",
    "X, y = make_moons(num_samples, shuffle=True, noise=noise_level)\n",
    "\n",
    "X[y==0, 1] += 0.15\n",
    "X[y==1, 1] += -0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plot_data_2d(X, y, colors=(plt.cm.Set1(1), plt.cm.Set1(0)), ax=ax)\n",
    "ax.set(xlim=(-2, 3), ylim=(-2, 2.5))\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(visible=True, which='both', color='gray', alpha=0.2, linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_scaler = StandardScaler()\n",
    "\n",
    "X_train_normalized = original_scaler.fit_transform(X_train)\n",
    "X_val_normalized = original_scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(\n",
    "    degree=5,\n",
    "    interaction_only=False,\n",
    "    include_bias=False\n",
    ")\n",
    "\n",
    "X_train_poly = polynomial_features.fit_transform(X_train_normalized)\n",
    "X_val_poly = polynomial_features.transform(X_val_normalized)\n",
    "\n",
    "num_features = X_train_poly.shape[1]\n",
    "print('No. features:', num_features)\n",
    "print('\\nFeatures:', polynomial_features.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_scaler = StandardScaler()\n",
    "\n",
    "X_train_final = polynomial_scaler.fit_transform(X_train_poly)\n",
    "X_val_final = polynomial_scaler.transform(X_val_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(\n",
    "    torch.tensor(X_train_final, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.int64)\n",
    ")\n",
    "\n",
    "val_set = TensorDataset(\n",
    "    torch.tensor(X_val_final, dtype=torch.float32),\n",
    "    torch.tensor(y_val, dtype=torch.int64)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=len(train_set),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=len(val_set),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logistic regression model\n",
    "model1 = nn.Linear(\n",
    "    in_features=num_features,\n",
    "    out_features=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.1)\n",
    "\n",
    "point_model = Classification(\n",
    "    model1,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_history = point_model.training(\n",
    "    num_epochs=500,\n",
    "    log_interval=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_train_loss, point_train_acc = point_model.test(train_loader)\n",
    "point_val_loss, point_val_acc = point_model.test(val_loader)\n",
    "\n",
    "print('Train loss: {:.4f}'.format(point_train_loss))\n",
    "print('Val. loss: {:.4f}'.format(point_val_loss))\n",
    "print('\\nTrain acc.: {:.4f}'.format(point_train_acc))\n",
    "print('Val. acc.: {:.4f}'.format(point_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(np.array(point_history['train_loss']), label='train', alpha=0.7)\n",
    "ax.plot(np.array(point_history['val_loss']), label='val.', alpha=0.7)\n",
    "ax.set(xlabel='epoch', ylabel='loss')\n",
    "ax.set_xlim((0, point_history['num_epochs']))\n",
    "ax.legend()\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variational logistic regression model\n",
    "model2 = VariationalLinear(\n",
    "    in_features=num_features,\n",
    "    out_features=1,\n",
    "    weight_std=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.1)\n",
    "\n",
    "post_model = VariationalClassification(\n",
    "    model2,\n",
    "    likelihood_type='Bernoulli'\n",
    ")\n",
    "\n",
    "post_model.compile_for_training(\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "post_history = post_model.training(\n",
    "    num_epochs=500,\n",
    "    num_samples=20,\n",
    "    log_interval=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_train_loss = post_model.test_loss(train_loader)\n",
    "post_train_acc = post_model.test_acc(train_loader)\n",
    "\n",
    "post_val_loss = post_model.test_loss(val_loader)\n",
    "post_val_acc = post_model.test_acc(val_loader)\n",
    "\n",
    "print('Train loss: {:.4f}'.format(post_train_loss))\n",
    "print('Val. loss: {:.4f}'.format(post_val_loss))\n",
    "print('\\nTrain acc.: {:.4f}'.format(post_train_acc))\n",
    "print('Val. acc.: {:.4f}'.format(post_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(-np.array(post_history['train_loss']), label='train', alpha=0.7)\n",
    "ax.plot(-np.array(post_history['val_loss']), label='val.', alpha=0.7)\n",
    "ax.set(xlabel='epoch', ylabel='ELBO')\n",
    "ax.set_xlim((0, post_history['num_epochs']))\n",
    "ax.legend()\n",
    "ax.grid(visible=True, which='both', color='lightgray', linestyle='-')\n",
    "ax.set_axisbelow(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(x):\n",
    "    '''Transform features.'''\n",
    "    x_normalized = original_scaler.transform(x)\n",
    "    x_poly = polynomial_features.transform(x_normalized)\n",
    "    x_final = polynomial_scaler.transform(x_poly)\n",
    "\n",
    "    x_tensor = torch.tensor(x_final, dtype=torch.float32)\n",
    "    return x_tensor\n",
    "\n",
    "@torch.no_grad()\n",
    "def point_prediction(x):\n",
    "    '''Compute normal point predictions.'''\n",
    "    x_tensor = transform_features(x)\n",
    "\n",
    "    point_model.train(False)\n",
    "\n",
    "    point_logits = point_model.predict(x_tensor.to(point_model.device))\n",
    "    point_probs = torch.sigmoid(point_logits)\n",
    "    return point_probs.cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def posterior_mean(x):\n",
    "    '''Predict with posterior mean weights.'''\n",
    "    x_tensor = transform_features(x)\n",
    "\n",
    "    post_model.sample(False)\n",
    "    post_model.train(False)\n",
    "\n",
    "    point_logits = post_model.predict(x_tensor.to(post_model.device))\n",
    "    point_probs = torch.sigmoid(point_logits)\n",
    "    return point_probs.cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def posterior_predictive(x, num_samples=1000):\n",
    "    '''Predict according to the posterior predictive distribution.'''\n",
    "    x_tensor = transform_features(x)\n",
    "\n",
    "    post_model.sample(True)\n",
    "    post_model.train(False)\n",
    "\n",
    "    sampled_logits = post_model.predict(x_tensor.to(post_model.device), num_samples)\n",
    "    sampled_probs = torch.sigmoid(sampled_logits)\n",
    "\n",
    "    post_mean = torch.mean(sampled_probs, axis=-1)\n",
    "    return post_mean.cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def posterior_uncertainty(x, num_samples=1000):\n",
    "    '''Compute the uncertainty associated with the posterior predictive.'''\n",
    "    x_tensor = transform_features(x)\n",
    "\n",
    "    post_model.sample(True)\n",
    "    post_model.train(False)\n",
    "\n",
    "    sampled_logits = post_model.predict(x_tensor.to(post_model.device), num_samples)\n",
    "    sampled_probs = torch.sigmoid(sampled_logits)\n",
    "\n",
    "    post_std = torch.std(sampled_probs, axis=-1)\n",
    "    return post_std.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "plot_data_2d(X_train, y_train, colors=(plt.cm.Set1(1), plt.cm.Set1(0)), ax=ax)\n",
    "ax.set(xlim=(-2, 3), ylim=(-2, 2.5))\n",
    "plot_function_2d(point_prediction, levels=(0.3, 0.5, 0.7), ax=ax)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title('Point predictions')\n",
    "ax.legend(loc='upper left')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "plot_data_2d(X_train, y_train, colors=(plt.cm.Set1(1), plt.cm.Set1(0)), ax=ax)\n",
    "ax.set(xlim=(-2, 3), ylim=(-2, 2.5))\n",
    "plot_function_2d(posterior_mean, levels=(0.3, 0.5, 0.7), ax=ax)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title('Posterior mean')\n",
    "ax.legend(loc='upper left')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "plot_data_2d(X_train, y_train, colors=(plt.cm.Set1(1), plt.cm.Set1(0)), ax=ax)\n",
    "ax.set(xlim=(-2, 3), ylim=(-2, 2.5))\n",
    "plot_function_2d(posterior_predictive, levels=(0.1, 0.3, 0.5, 0.7, 0.9), ax=ax)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title('Posterior predictions')\n",
    "ax.legend(loc='upper left')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4.5))\n",
    "plot_data_2d(X_train, y_train, colors=(plt.cm.Set1(1), plt.cm.Set1(0)), ax=ax)\n",
    "ax.set(xlim=(-2, 3), ylim=(-2, 2.5))\n",
    "plot_function_2d(posterior_uncertainty, levels=np.linspace(0.1, 0.9, 9), ax=ax)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title('Posterior uncertainty')\n",
    "ax.legend(loc='upper left')\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
